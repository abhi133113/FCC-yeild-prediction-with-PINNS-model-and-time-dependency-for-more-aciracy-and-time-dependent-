import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Step 1: Data Generation
np.random.seed(42)
data = pd.DataFrame(np.random.uniform(low=[5, 30000, 200, 400], high=[10, 50000, 400, 800], size=(100, 4)),
                    columns=['Catalyst_Oil_Ratio', 'Feed_Rate', 'Feed_Temperature', 'Catalyst_Temperature'])
data['Yield'] = np.random.uniform(0.7, 0.9, 100)
data['Time'] = np.random.uniform(1, 100, 100)

# Step 2: Features and Labels
X = data[['Catalyst_Oil_Ratio', 'Feed_Rate', 'Feed_Temperature', 'Catalyst_Temperature', 'Time']]
y = data['Yield']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Random Forest Model
rf = RandomForestRegressor()
rf.fit(X_train, y_train)
yield_pred_rf = rf.predict(X_test)

# Random Forest Metrics
mse_rf = mean_squared_error(y_test, yield_pred_rf)
r2_rf = r2_score(y_test, yield_pred_rf)
print(f'Random Forest - MSE: {mse_rf}, R²: {r2_rf}')

# Step 4: Artificial Neural Network (ANN)
ann = tf.keras.models.Sequential([
    tf.keras.layers.InputLayer(input_shape=(5,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='linear')
])

ann.compile(optimizer='adam', loss='mse')
ann.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)
yield_pred_ann = ann.predict(X_test)

# ANN Metrics
mse_ann = mean_squared_error(y_test, yield_pred_ann)
r2_ann = r2_score(y_test, yield_pred_ann)
print(f'ANN - MSE: {mse_ann}, R²: {r2_ann}')

# Step 5: Physics-Informed Neural Networks (PINN)
# Define physical loss function (example constraint)
def physical_constraint(y_pred, params):
    with tf.GradientTape() as tape:
        tape.watch(params[:, 0])  # Derivative w.r.t Catalyst to Oil Ratio
        y_pred_tape = y_pred
    dy_dcatalyst_ratio = tape.gradient(y_pred_tape, params[:, 0])
    loss_physics = tf.reduce_mean(tf.square(dy_dcatalyst_ratio - 0.5))  # Example physics-based loss
    return loss_physics

# PINN Model Setup
inputs = tf.keras.Input(shape=(4,))
x = tf.keras.layers.Dense(64, activation='relu')(inputs)
x = tf.keras.layers.Dense(32, activation='relu')(x)
outputs = tf.keras.layers.Dense(1, activation='linear')(x)
pinn = tf.keras.Model(inputs=inputs, outputs=outputs)
pinn.compile(optimizer='adam', loss='mse')

# Step 6: Train PINN with Custom Loss
class CustomLoss(tf.keras.losses.Loss):
    def call(self, y_true, y_pred):
        mse_loss = tf.keras.losses.mean_squared_error(y_true, y_pred)
        phys_loss = physical_constraint(y_pred, X_train)
        return mse_loss + phys_loss

pinn.compile(optimizer='adam', loss=CustomLoss())
pinn.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)
yield_pred_pinn = pinn.predict(X_test)

# PINN Metrics
mse_pinn = mean_squared_error(y_test, yield_pred_pinn)
r2_pinn = r2_score(y_test, yield_pred_pinn)
print(f'PINN - MSE: {mse_pinn}, R²: {r2_pinn}')

# Step 7: Plotting Results
plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Actual Yield')
plt.plot(yield_pred_rf, label='Random Forest Predicted Yield')
plt.plot(yield_pred_ann, label='ANN Predicted Yield')
plt.plot(yield_pred_pinn, label='PINN Predicted Yield')
plt.xlabel('Samples')
plt.ylabel('Yield')
plt.legend()
plt.show()
